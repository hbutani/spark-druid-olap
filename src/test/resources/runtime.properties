druid.service=druid/broker
druid.port=8082

# HTTP server threads
druid.broker.http.numConnections=25
druid.server.http.numThreads=6

# Processing threads and buffers
druid.processing.buffer.sizeBytes=256000000
druid.processing.numThreads=2

# We enable using the local query cache here
druid.broker.cache.useCache=true
druid.broker.cache.populateCache=true
druid.cache.type=local
druid.cache.sizeInBytes=2000000000



druid.service=druid/coordinator
druid.port=8081

druid.coordinator.startDelay=PT30S
druid.coordinator.period=PT30S




druid.service=druid/historical
druid.port=8083

# HTTP server threads
druid.server.http.numThreads=25

# Processing threads and buffers
druid.processing.buffer.sizeBytes=256000000
druid.processing.numThreads=2


# maxSize should reflect the performance you want.
# Druid memory maps segments.
# memory_for_segments = total_memory - heap_size - (processing.buffer.sizeBytes * (processing.numThreads+1)) - JVM overhead (~1G)
# The greater the memory/disk ratio, the better performance you should see
druid.segmentCache.locations=[{"path": "/tmp/druid/indexCache", "maxSize"\: 10000000000}]
druid.server.maxSize=10000000000


druid.query.groupBy.maxResults=1000000


#druid.historical.cache.useCache=true
#druid.historical.cache.populateCache=true
#druid.historical.cache.unCacheable=[]
